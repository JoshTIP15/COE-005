{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6sAVG5GTfkb"
      },
      "outputs": [],
      "source": [
        "#Import important libraries\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import linear_model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from numpy import loadtxt\n",
        "\n",
        "#Loading dataset\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "df = pd.concat([train_df, test_df], axis=0, sort=True)\n",
        "\n",
        "#Analyzing data\n",
        "train_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Display summary statistics\n",
        "train_df.describe()"
      ],
      "metadata": {
        "id": "pKztAluhUpZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We will get the first 8 rows of the dataset\n",
        "train_df.head(8)"
      ],
      "metadata": {
        "id": "qUfCQmHjUpXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding what data are not present\n",
        "total = train_df.isnull().sum().sort_values(ascending=False)\n",
        "percent_1 = train_df.isnull().sum()/train_df.isnull().count()*100\n",
        "percent_2 = (round(percent_1, 1)).sort_values(ascending=False)\n",
        "missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\n",
        "missing_data.head(5)"
      ],
      "metadata": {
        "id": "YKK3AwhVUpU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Displaying the array of all variables\n",
        "train_df.columns.values"
      ],
      "metadata": {
        "id": "su2B8qvSUpRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Determining what variable will give a high survival rate\n",
        "#Sex and age are one of the important variables\n",
        "survived = 'survived'\n",
        "not_survived = 'not survived'\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10, 4))\n",
        "women = train_df[train_df['Sex']=='female']\n",
        "men = train_df[train_df['Sex']=='male']\n",
        "ax = sns.distplot(women[women['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[0], kde =False)\n",
        "ax = sns.distplot(women[women['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[0], kde =False)\n",
        "ax.legend()\n",
        "ax.set_title('Female')\n",
        "ax = sns.distplot(men[men['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[1], kde = False)\n",
        "ax = sns.distplot(men[men['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[1], kde = False)\n",
        "ax.legend()\n",
        "_ = ax.set_title('Male')"
      ],
      "metadata": {
        "id": "lsQpYI9nUpNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Embarked and Pclass are also important variables\n",
        "FacetGrid = sns.FacetGrid(train_df, row='Embarked', size=4.5, aspect=1.6)\n",
        "FacetGrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette=None,  order=None, hue_order=None )\n",
        "FacetGrid.add_legend()"
      ],
      "metadata": {
        "id": "5Gi9NHN1Ys--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x='Pclass', y='Survived', data=train_df)"
      ],
      "metadata": {
        "id": "8ncqbBotUpHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating another Pclass plot\n",
        "grid = sns.FacetGrid(train_df, col='Survived', row='Pclass', height=2.2, aspect=1.6)\n",
        "grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n",
        "grid.add_legend();"
      ],
      "metadata": {
        "id": "7N4YD9elUpFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SibSp and Parch are another variable that shows total number of relatives\n",
        "data = [train_df, test_df]\n",
        "for dataset in data:\n",
        "    dataset['relatives'] = dataset['SibSp'] + dataset['Parch']\n",
        "    dataset.loc[dataset['relatives'] > 0, 'not_alone'] = 0\n",
        "    dataset.loc[dataset['relatives'] == 0, 'not_alone'] = 1\n",
        "    dataset['not_alone'] = dataset['not_alone'].astype(int)\n",
        "train_df['not_alone'].value_counts()"
      ],
      "metadata": {
        "id": "PH6fHZ8YUpB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "axes = sns.factorplot('relatives','Survived', data=train_df, aspect = 2.5, )"
      ],
      "metadata": {
        "id": "ETOt_waPUo_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Preprocessing\n",
        "#Removing Passenger Id from the data\n",
        "train_df = train_df.drop(['PassengerId'], axis=1)"
      ],
      "metadata": {
        "id": "IL93Hxy8Uo8Y"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dealing with the missing data\n",
        "#Missing data: Cabin\n",
        "import re\n",
        "deck = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\n",
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset['Cabin'] = dataset['Cabin'].fillna(\"U0\")\n",
        "    dataset['Deck'] = dataset['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n",
        "    dataset['Deck'] = dataset['Deck'].map(deck)\n",
        "    dataset['Deck'] = dataset['Deck'].fillna(0)\n",
        "    dataset['Deck'] = dataset['Deck'].astype(int)\n",
        "\n",
        "train_df = train_df.drop(['Cabin'], axis=1)\n",
        "test_df = test_df.drop(['Cabin'], axis=1)"
      ],
      "metadata": {
        "id": "nYj5D4XpUo5X"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Missing Data: Age\n",
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    mean = train_df[\"Age\"].mean()\n",
        "    std = test_df[\"Age\"].std()\n",
        "    is_null = dataset[\"Age\"].isnull().sum()\n",
        "    # compute random numbers between the mean, std and is_null\n",
        "    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n",
        "    # fill NaN values in Age column with random values generated\n",
        "    age_slice = dataset[\"Age\"].copy()\n",
        "    age_slice[np.isnan(age_slice)] = rand_age\n",
        "    dataset[\"Age\"] = age_slice\n",
        "    dataset[\"Age\"] = train_df[\"Age\"].astype(int)\n",
        "train_df[\"Age\"].isnull().sum()"
      ],
      "metadata": {
        "id": "wHcpNdv_Uo28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Missing Data: Embarked\n",
        "train_df['Embarked'].describe()"
      ],
      "metadata": {
        "id": "uVBQXyfGUo0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common_value = 'S'\n",
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset['Embarked'] = dataset['Embarked'].fillna(common_value)"
      ],
      "metadata": {
        "id": "desBBv22Uox2"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting Features\n",
        "train_df.info()"
      ],
      "metadata": {
        "id": "fYRxClNsUouh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fare\n",
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset['Fare'] = dataset['Fare'].fillna(0)\n",
        "    dataset['Fare'] = dataset['Fare'].astype(int)"
      ],
      "metadata": {
        "id": "z7Bx02AcUor2"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Name\n",
        "data = [train_df, test_df]\n",
        "titles = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
        "\n",
        "for dataset in data:\n",
        "    # extract titles\n",
        "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "    # replace titles with a more common title or as Rare\n",
        "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr',\\\n",
        "                                            'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
        "    # convert titles into numbers\n",
        "    dataset['Title'] = dataset['Title'].map(titles)\n",
        "    # filling NaN with 0, to get safe\n",
        "    dataset['Title'] = dataset['Title'].fillna(0)\n",
        "train_df = train_df.drop(['Name'], axis=1)\n",
        "test_df = test_df.drop(['Name'], axis=1)"
      ],
      "metadata": {
        "id": "hUNpFlk5UopV"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sex\n",
        "genders = {\"male\": 0, \"female\": 1}\n",
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset['Sex'] = dataset['Sex'].map(genders)"
      ],
      "metadata": {
        "id": "c6D-qHMxUoml"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ticket\n",
        "train_df['Ticket'].describe()"
      ],
      "metadata": {
        "id": "S1m6uYp4Uojr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.drop(['Ticket'], axis=1)\n",
        "test_df = test_df.drop(['Ticket'], axis=1)"
      ],
      "metadata": {
        "id": "6gFmLqNHUogn"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Embarked\n",
        "ports = {\"S\": 0, \"C\": 1, \"Q\": 2}\n",
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset['Embarked'] = dataset['Embarked'].map(ports)"
      ],
      "metadata": {
        "id": "guzhPKRsUoeH"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating Categories\n",
        "#Age\n",
        "data = [train_df, test_df]\n",
        "for dataset in data:\n",
        "    dataset['Age'] = dataset['Age'].astype(int)\n",
        "    dataset.loc[ dataset['Age'] <= 11, 'Age'] = 0\n",
        "    dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 1\n",
        "    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 2\n",
        "    dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 27), 'Age'] = 3\n",
        "    dataset.loc[(dataset['Age'] > 27) & (dataset['Age'] <= 33), 'Age'] = 4\n",
        "    dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 40), 'Age'] = 5\n",
        "    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 66), 'Age'] = 6\n",
        "    dataset.loc[ dataset['Age'] > 66, 'Age'] = 6\n",
        "\n",
        "# let's see how it's distributed train_df['Age'].value_counts()"
      ],
      "metadata": {
        "id": "tnDOKjFDUoa3"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fare\n",
        "train_df.head(10)"
      ],
      "metadata": {
        "id": "7dpa7ogwUoX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
        "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
        "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
        "    dataset.loc[(dataset['Fare'] > 31) & (dataset['Fare'] <= 99), 'Fare']   = 3\n",
        "    dataset.loc[(dataset['Fare'] > 99) & (dataset['Fare'] <= 250), 'Fare']   = 4\n",
        "    dataset.loc[ dataset['Fare'] > 250, 'Fare'] = 5\n",
        "    dataset['Fare'] = dataset['Fare'].astype(int)"
      ],
      "metadata": {
        "id": "JKlR0xJwUoSz"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating new features\n",
        "data = [train_df, test_df]\n",
        "for dataset in data:\n",
        "    dataset['Age_Class']= dataset['Age']* dataset['Pclass']"
      ],
      "metadata": {
        "id": "JvtU2xYmUoOO"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset in data:\n",
        "    dataset['Fare_Per_Person'] = dataset['Fare']/(dataset['relatives']+1)\n",
        "    dataset['Fare_Per_Person'] = dataset['Fare_Per_Person'].astype(int)\n",
        "\n",
        "train_df.head(10)"
      ],
      "metadata": {
        "id": "S9LjdjZwUoGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Building Models\n",
        "X_train = train_df.drop(\"Survived\", axis=1)\n",
        "Y_train = train_df[\"Survived\"]\n",
        "X_test  = test_df.drop(\"PassengerId\", axis=1).copy()"
      ],
      "metadata": {
        "id": "9x48RdSCWDLI"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest\n",
        "random_forest = RandomForestClassifier(n_estimators=100)\n",
        "random_forest.fit(X_train, Y_train)\n",
        "\n",
        "Y_prediction = random_forest.predict(X_test)\n",
        "\n",
        "random_forest.score(X_train, Y_train)\n",
        "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
        "\n",
        "#Logistic Regression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, Y_train)\n",
        "\n",
        "Y_prediction2 = logreg.predict(X_test)\n",
        "\n",
        "acc_log = round(logreg.score(X_train, Y_train) * 100, 2)"
      ],
      "metadata": {
        "id": "un2DAUDbWDC_"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy\n",
        "results = pd.DataFrame({\n",
        "    'Model': ['Random Forest', 'Logistic Regression'],\n",
        "    'Score': [acc_random_forest, acc_log]})\n",
        "result_df = results.sort_values(by='Score', ascending=False)\n",
        "result_df = result_df.set_index('Score')\n",
        "result_df.head(9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "O58mnX1DWC7g",
        "outputId": "20af1fa3-2291-4580-b778-fa0fb93b80d8"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Model\n",
              "Score                     \n",
              "92.82        Random Forest\n",
              "81.59  Logistic Regression"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-358538b9-71a8-44c5-a24e-124c78b977f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Score</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>92.82</th>\n",
              "      <td>Random Forest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81.59</th>\n",
              "      <td>Logistic Regression</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-358538b9-71a8-44c5-a24e-124c78b977f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-358538b9-71a8-44c5-a24e-124c78b977f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-358538b9-71a8-44c5-a24e-124c78b977f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the training data into folds\n",
        "from sklearn.model_selection import cross_val_score\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "scores = cross_val_score(rf, X_train, Y_train, cv=10, scoring = \"accuracy\")\n",
        "print(\"Scores:\", scores)\n",
        "print(\"Mean:\", scores.mean())\n",
        "print(\"Standard Deviation:\", scores.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVOEeRnEWCy_",
        "outputId": "dd9ee57f-66a0-4f1d-fbc9-8d8305c1bd9b"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores: [0.76666667 0.84269663 0.73033708 0.83146067 0.87640449 0.82022472\n",
            " 0.82022472 0.78651685 0.83146067 0.83146067]\n",
            "Mean: 0.8137453183520599\n",
            "Standard Deviation: 0.03962895490985601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "importances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(random_forest.feature_importances_,3)})\n",
        "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
        "importances.head(15)"
      ],
      "metadata": {
        "id": "EfBs64lWWCqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importances.plot.bar()"
      ],
      "metadata": {
        "id": "tFpRQFbsWCiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping unnecessary variables \n",
        "train_df  = train_df.drop(\"not_alone\", axis=1)\n",
        "test_df  = test_df.drop(\"not_alone\", axis=1)\n",
        "\n",
        "train_df  = train_df.drop(\"Parch\", axis=1)\n",
        "test_df  = test_df.drop(\"Parch\", axis=1)"
      ],
      "metadata": {
        "id": "M5jP07BBeH5o"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Random Forest again\n",
        "random_forest = RandomForestClassifier(n_estimators=100, oob_score = True)\n",
        "random_forest.fit(X_train, Y_train)\n",
        "Y_prediction = random_forest.predict(X_test)\n",
        "\n",
        "random_forest.score(X_train, Y_train)\n",
        "\n",
        "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
        "print(round(acc_random_forest,2,), \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp1pK0p5fc5e",
        "outputId": "9902df0d-fb42-4265-c47f-8b56747136ae"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92.82 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"oob score:\", round(random_forest.oob_score_, 4)*100, \"%\")"
      ],
      "metadata": {
        "id": "zVwvNy6ufnem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Random Forest again\n",
        "random_forest = RandomForestClassifier(criterion = \"gini\", \n",
        "                                       min_samples_leaf = 1, \n",
        "                                       min_samples_split = 10,   \n",
        "                                       n_estimators=100, \n",
        "                                       max_features='auto', \n",
        "                                       oob_score=True, \n",
        "                                       random_state=1, \n",
        "                                       n_jobs=-1)\n",
        "\n",
        "random_forest.fit(X_train, Y_train)\n",
        "Y_prediction = random_forest.predict(X_test)\n",
        "\n",
        "random_forest.score(X_train, Y_train)\n",
        "\n",
        "print(\"oob score:\", round(random_forest.oob_score_, 4)*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7ay_cKCWCa0",
        "outputId": "bff50bfb-53f8-4a10-8dc9-aa9de6e0f665"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "oob score: 82.38 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Making a confusion matrix\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "predictions = cross_val_predict(random_forest, X_train, Y_train, cv=3)\n",
        "confusion_matrix(Y_train, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtxfB2szWCUH",
        "outputId": "9c0bbc72-4452-452f-b827-eb5e34d9b338"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[483,  66],\n",
              "       [ 93, 249]])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Precision and recall score\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "print(\"Precision:\", precision_score(Y_train, predictions))\n",
        "print(\"Recall:\",recall_score(Y_train, predictions))"
      ],
      "metadata": {
        "id": "oXCx4yo9iwuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining a keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_shape=(X_train.shape[1],), activation='sigmoid'))\n",
        "model.add(Dense(12, input_shape=(8,), activation='relu')) \n",
        "model.add(Dense(8, activation='relu')) \n",
        "model.add(Dense(1, activation='sigmoid')) "
      ],
      "metadata": {
        "id": "cn9z1ifaWB7T"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compiling the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) "
      ],
      "metadata": {
        "id": "U5fC7rVCWi6w"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the model on the dataset\n",
        "model.fit(X_train, Y_train, epochs=150, batch_size=10)"
      ],
      "metadata": {
        "id": "5eDcAIM2WjP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy of the model\n",
        "_, accuracy = model.evaluate(X_train, Y_train)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkWe_d2HWjAF",
        "outputId": "1bd1824e-e5af-401f-88fe-9a3109c4e131"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28/28 [==============================] - 0s 847us/step - loss: 0.3577 - accuracy: 0.8575\n",
            "Accuracy: 85.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Out of the two algorithms used, Random Forest got the highest accuracy of 92.82%. Next is that I conduct a K-Fold Cross Validation and the algorithm got an average accuracy of 81% with a standard deviation of 4%\n",
        "#After that I dropped not alone and parch from the dataset because it is not that important. After removing the said variable is that we train the random forest again and it got the same accuracy.\n",
        "#As a conclusion, using all algorithms and getting the highest accuracy can make your prediction better, and after that remove unnecessary variables and train the algorithm again for better accuracy and precision."
      ],
      "metadata": {
        "id": "m9_Kwnw-j__2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}