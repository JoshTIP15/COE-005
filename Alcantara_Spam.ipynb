{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "7AIZ7Y3PvPph"
      },
      "outputs": [],
      "source": [
        "#Import important libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense, Dropout, LSTM, Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading Dataset\n",
        "data = pd.read_csv('spam.csv',encoding='latin-1')\n",
        "#Removing unnecessary data\n",
        "data = data.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
        "#Renaming data\n",
        "data = data.rename(columns={\"v1\":'label', \"v2\":'text'})\n",
        "print(data.head())\n",
        "tags = data[\"label\"]\n",
        "texts = data[\"text\"]"
      ],
      "metadata": {
        "id": "ERXSnvUGy5Fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_msg = pd.read_csv('output_spam.csv',encoding='latin-1')\n",
        "predict_msg.head()"
      ],
      "metadata": {
        "id": "4SYE4iyyIQtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Summary Statistics\n",
        "data.describe()"
      ],
      "metadata": {
        "id": "FpD8dDHjy5Cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Looking for duplicate messages\n",
        "duplicatedRow = data[data.duplicated()]\n",
        "print(duplicatedRow[:5])"
      ],
      "metadata": {
        "id": "HwoqCAWcy4_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.groupby('label').describe().T"
      ],
      "metadata": {
        "id": "0vKv3Yooy49I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get all the ham and spam emails\n",
        "ham_msg = data[data.label =='ham']\n",
        "spam_msg = data[data.label=='spam']\n",
        "#Create numpy list to visualize using wordcloud\n",
        "ham_msg_text = \" \".join(ham_msg.text.to_numpy().tolist())\n",
        "spam_msg_text = \" \".join(spam_msg.text.to_numpy().tolist())"
      ],
      "metadata": {
        "id": "wmy4tI_Xy4wP"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Wordcloud of ham messages\n",
        "ham_msg_cloud = WordCloud(width =520, height =260, stopwords=STOPWORDS,max_font_size=50, background_color =\"black\", colormap='Blues').generate(ham_msg_text)\n",
        "plt.figure(figsize=(16,10))\n",
        "plt.imshow(ham_msg_cloud, interpolation='bilinear')\n",
        "plt.axis('off') \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-w4CU7JUy4nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Wordcloud of spam messages\n",
        "spam_msg_cloud = WordCloud(width =520, height =260, stopwords=STOPWORDS,max_font_size=50, background_color =\"black\", colormap='Blues').generate(spam_msg_text)\n",
        "plt.figure(figsize=(16,10))\n",
        "plt.imshow(spam_msg_cloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ywpHVVjB2JG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the data to display imbalance data\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.countplot(data.label)\n",
        "#Percentage of spam messages\n",
        "(len(spam_msg)/len(ham_msg))*100 # 15.48%"
      ],
      "metadata": {
        "id": "-0JE1O5y2c2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fixing the imbalance by downsampling\n",
        "ham_msg_df = ham_msg.sample(n = len(spam_msg), random_state = 44)\n",
        "spam_msg_df = spam_msg\n",
        "print(ham_msg_df.shape, spam_msg_df.shape)"
      ],
      "metadata": {
        "id": "cizRSrOO2dWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a dataframe\n",
        "msg_df = ham_msg_df.append(spam_msg_df).reset_index(drop=True)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.countplot(msg_df.label)\n",
        "plt.title('Distribution of ham and spam email messages (after downsampling)')\n",
        "plt.xlabel('Message types')"
      ],
      "metadata": {
        "id": "XsAkdeQK2dN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the text length\n",
        "msg_df['text_length'] = msg_df['text'].apply(len)\n",
        "#Calculate average length by label types\n",
        "labels = msg_df.groupby('label').mean()\n",
        "labels"
      ],
      "metadata": {
        "id": "si8Ktrzs2c87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparing train/test data and pre-process text\n",
        "msg_df['msg_type']= msg_df['label'].map({'ham': 0, 'spam': 1})\n",
        "msg_label = msg_df['msg_type'].values\n",
        "#Splitting data into train and test\n",
        "train_msg, test_msg, train_labels, test_labels = train_test_split(msg_df['text'], msg_label, test_size=0.2, random_state=434)"
      ],
      "metadata": {
        "id": "AOO7z8bt2c6M"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining hyperparameters\n",
        "max_len = 50 \n",
        "trunc_type = \"post\" \n",
        "padding_type = \"post\" \n",
        "oov_tok = \"<OOV>\" \n",
        "vocab_size = 500"
      ],
      "metadata": {
        "id": "Vg1fcvsS3lpi"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert text into numerical representation by using tokenization\n",
        "tokenizer = Tokenizer(num_words = vocab_size, char_level=False, oov_token = oov_tok)\n",
        "tokenizer.fit_on_texts(train_msg)"
      ],
      "metadata": {
        "id": "Sj9UnLOy3lgy"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using word_index \n",
        "word_index = tokenizer.word_index\n",
        "word_index"
      ],
      "metadata": {
        "id": "mO7EOnAv3lYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking how many words \n",
        "tot_words = len(word_index)\n",
        "print('There are %s unique tokens in training data. ' % tot_words)"
      ],
      "metadata": {
        "id": "MT7MRAy53lMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sequencing and padding\n",
        "training_sequences = tokenizer.texts_to_sequences(train_msg)\n",
        "training_padded = pad_sequences (training_sequences, maxlen = max_len, padding = padding_type, truncating = trunc_type )\n",
        "testing_sequences = tokenizer.texts_to_sequences(test_msg)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen = max_len,\n",
        "padding = padding_type, truncating = trunc_type)"
      ],
      "metadata": {
        "id": "TKF_Oya733ZL"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Shape of train tensor\n",
        "print('Shape of training tensor: ', training_padded.shape)\n",
        "print('Shape of testing tensor: ', testing_padded.shape)"
      ],
      "metadata": {
        "id": "oSSbvmW_33Vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Before padding\n",
        "len(training_sequences[0]), len(training_sequences[1])"
      ],
      "metadata": {
        "id": "NNT97Gtj33QU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#After padding\n",
        "len(training_padded[0]), len(training_padded[1])"
      ],
      "metadata": {
        "id": "xVYYVyOs33MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_padded[0])"
      ],
      "metadata": {
        "id": "Ezpzy63t33GN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining hyperparameters for the Dense Model\n",
        "vocab_size = 500 \n",
        "embeding_dim = 16\n",
        "drop_value = 0.2\n",
        "n_dense = 24"
      ],
      "metadata": {
        "id": "f2aE_TP833A_"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dense model architecture\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embeding_dim, input_length=max_len))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(24, activation='relu'))\n",
        "model.add(Dropout(drop_value))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "bCKlDGFa6G6L"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "0Dkf31aP6G0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compiling the Dense model\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam' ,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "3GhCojPU6Gte"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the dense spam detector model\n",
        "num_epochs = 30\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
        "history = model.fit(training_padded, train_labels, epochs=num_epochs, validation_data=(testing_padded, test_labels),callbacks =[early_stop], verbose=2)"
      ],
      "metadata": {
        "id": "0k8COHp96GmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model performance on test data \n",
        "model.evaluate(testing_padded, test_labels)"
      ],
      "metadata": {
        "id": "BsS4Zt7q6Gey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Read as a dataframe \n",
        "metrics = pd.DataFrame(history.history)\n",
        "#Renaming column\n",
        "metrics.rename(columns = {'loss': 'Training_Loss', 'accuracy': 'Training_Accuracy', 'val_loss': 'Validation_Loss', 'val_accuracy': 'Validation_Accuracy'}, inplace = True)\n",
        "def plot_graphs1(var1, var2, string):\n",
        "    metrics[[var1, var2]].plot()\n",
        "    plt.title('Training and Validation ' + string)\n",
        "    plt.xlabel ('Number of epochs')\n",
        "    plt.ylabel(string)\n",
        "    plt.legend([var1, var2])"
      ],
      "metadata": {
        "id": "cEx92l8H6GW6"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display long string \n",
        "pd.options.display.max_colwidth=100\n",
        "predict_msg[:20]"
      ],
      "metadata": {
        "id": "zwaEftdd67Kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "189Z6IERFlcq"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining prediction function\n",
        "def predict_spam(predict_msg):\n",
        "    new_seq = tokenizer.texts_to_sequences(predict_msg)\n",
        "    padded = pad_sequences(new_seq, maxlen =max_len,\n",
        "                      padding = padding_type,\n",
        "                      truncating=trunc_type)\n",
        "    return (model.predict(padded))\n",
        "predict_spam(predict_msg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJvMtFCf67B0",
        "outputId": "379cf9cf-0840-41eb-9c90-46ffd48b4556"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01467556],\n",
              "       [0.09514403]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CnONq6-3666p"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "predict_spam('output_spam.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1eSOtTi660O",
        "outputId": "edf8dcce-dad1-438b-d71f-bf54874e71e6"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01467556],\n",
              "       [0.01094931],\n",
              "       [0.04646036],\n",
              "       [0.01467556],\n",
              "       [0.01094931],\n",
              "       [0.04646036],\n",
              "       [0.01183754],\n",
              "       [0.00651857],\n",
              "       [0.01467556],\n",
              "       [0.01850682],\n",
              "       [0.02487409],\n",
              "       [0.01183754],\n",
              "       [0.02569854],\n",
              "       [0.00651857],\n",
              "       [0.00542918]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    }
  ]
}